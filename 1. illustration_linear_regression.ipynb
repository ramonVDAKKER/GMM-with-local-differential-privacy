{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of locally differentially private linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates that naively using OLS on locally differentially private data leads to an inconsistent estimator. It is explained how the estimator should be adapted in order to obtain consistency. \n",
    "\n",
    "This approach is, however, specific to linear regression. The second notebook demonstrates how one should adapt a Generalized Method of Moments estimator in order to deal with locally differentially private data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b2cb4703449a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnoise_generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msimulate\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from utils import noise_generators\n",
    "from utils import simulate as sim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate a dataset according to a univariate linear regression model $Y=\\alpha + \\beta X + \\varepsilon$. The regressor $X\\sim N(\\mu_X, \\sigma^2)$ and the innovation $\\epsilon$ is drawn (independently from $X$) from a Logistic distribution with mean zero. The variance is set in such a manner that the $R^2$ in the population, $R^2= \\beta^2 \\operatorname{var}(X)/(\\beta^2 \\operatorname{var}(X) + \\operatorname{var}(\\varepsilon))$, is equal to the specified value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "variance_X = 3\n",
    "mu_X = 4\n",
    "alpha = 2\n",
    "beta = .5\n",
    "desired_R_squared = .7\n",
    "data_df = sim.univariate_linear_regression(mu_X, variance_X, alpha, beta, desired_R_squared, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.plot.scatter(x=\"X\", y=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit OLS on 'true' dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using statsmodels we estimate the parameters using OLS. Please compare the parameter estimates and the R-squared to the specification above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_results = smf.ols(\"Y ~ 1 + X\", data=data_df).fit()\n",
    "print(ols_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using OLS on the locally private data does not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will investigate what happens if we use OLS on locally differentially private data. This basically means that instead of of $(Y_i,X_i)$ we will observe $(Y_i + \\eta_i, X_i + u_i)$, where $\\eta_i$ and $u_i$ are independent random variables (which are also independent over $i$).\n",
    "\n",
    "Generate locally differentially private data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = 3\n",
    "epsilon = 6\n",
    "private_data_df = noise_generators.add_noise_laplace_mechanism(data_df, epsilon, \n",
    "                                sensitivity, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect first row of dataset and compare to \"true data\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Locally differentially private data:\")\n",
    "display(private_data_df.head(3))\n",
    "print(\"True data:\")\n",
    "display(data_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using OLS on the locally private data does not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply OLS to the LDP dataset, then we typically obtain estimates that are far off the true parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model \n",
    "ols_results = smf.ols(\"Y ~ 1 + X\", data=private_data_df).fit()\n",
    "print(ols_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Adapt the OLS estimator in order to deal with local differential privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear regression we can use two moment conditions:  $0=\\mathbb{E}[ Y -\\alpha -\\beta X]$ and $0=\\mathbb{E}[ XY -\\alpha X -\\beta X^2]$. These moment conditions can be solved analytically. We need to receive data on $Y$, $X$, $XY$, and $X^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first add the additional columns $XY$ and $X^2$ to the true dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"X * Y\"] = data_df[\"X\"] * data_df[\"Y\"]\n",
    "data_df[\"X^2\"] = data_df[\"X\"] * data_df[\"X\"]\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we assume that we can obtain a local differentially private version of each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_data_df = noise_generators.add_noise_laplace_mechanism(data_df, epsilon, sensitivity, seed=123)\n",
    "private_data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply our moment estimator. First on the true data (which yields the same outputs as statsmodels) and after that on the locally differentially private dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_MM(Y, X, X_times_Y, X_squared):\n",
    "    hat_beta = (X_times_Y.mean() - X.mean() * Y.mean()) / (X_squared.mean() - X.mean() ** 2)\n",
    "    hat_alpha = Y.mean() - hat_beta * X.mean()\n",
    "    return hat_alpha, hat_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " linear_regression_MM(data_df[\"Y\"], data_df[\"X\"], data_df[\"X * Y\"], data_df[\"X^2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " linear_regression_MM(private_data_df[\"Y\"], private_data_df[\"X\"], private_data_df[\"X * Y\"], private_data_df[\"X^2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the results are quite close. It can indeed be proved that the above estimator, based upon locally differentially private data, is consistent. And, as you would expect, its variance exceeds the variance of OLS based upon the \"true data\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
